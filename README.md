# Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-training of Deep Networks

Official repository for "Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-training of Deep Networks" which presents the method MKDT.

## Obtaining Teacher Model 


## Generating Expert Trajectories

```
python 
```

## Distilling Dataset

```
python 
```

## Evaluating Distilled Dataset

```
python 
```

## Bibtex
